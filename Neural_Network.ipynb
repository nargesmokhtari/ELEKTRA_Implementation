{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Vectorizing the images"
      ],
      "metadata": {
        "id": "fdSfEHdeXM0m"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2T9XQe4sXI1H"
      },
      "outputs": [],
      "source": [
        "def vertorizing_png_imges(address):\n",
        "  # Load the PNG image\n",
        "  image = Image.open(address)\n",
        "\n",
        "  # Convert the image to RGB mode\n",
        "  image = image.convert('RGB')\n",
        "\n",
        "  # Resize the image to match the input size expected by the CNN\n",
        "  desired_width = 33\n",
        "  desired_height = 21\n",
        "  image = image.resize((desired_width, desired_height))\n",
        "\n",
        "  # Convert the image to a NumPy array\n",
        "  image_array = np.array(image)\n",
        "\n",
        "  # Normalize the array\n",
        "  image_array = image_array.astype('float32') / 255.0\n",
        "\n",
        "  return image_array"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_path_test = \"/content/EKM_dataset/test/\"\n",
        "base_path_train = \"/content/EKM_dataset/train/\""
      ],
      "metadata": {
        "id": "65iwZKV_XS03"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_x = []\n",
        "train_y = []\n",
        "\n",
        "test_x = []\n",
        "test_y = []"
      ],
      "metadata": {
        "id": "jBVKcroHXTrQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train data for cnn network input (x_train, y_train)\n",
        "\n",
        "# Get a list of all files in the <<train>> directory\n",
        "images_names = os.listdir(base_path_train)\n",
        "\n",
        "before_run_time = datetime.now()\n",
        "\n",
        "# Get train_x by vectorization\n",
        "# and train_y by name of each person in the each image name\n",
        "for index, img_name in enumerate(images_names):\n",
        "\n",
        "    img_vector = vertorizing_png_imges(base_path_train + img_name)\n",
        "    train_x.append(img_vector)\n",
        "\n",
        "    img_name = img_name.split(\"-\")\n",
        "    label = img_name[-2]\n",
        "    train_y.append(label)\n",
        "\n",
        "    progress_bar(index, \"train\")\n",
        "\n",
        "after_run_time = datetime.now()\n",
        "diff = after_run_time - before_run_time\n",
        "print(f\"This cell took {int(diff.seconds / 60)} minutes to run.\")"
      ],
      "metadata": {
        "id": "8RaVxYEmXVz2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test data for cnn network input (x_test, y_test)\n",
        "\n",
        "# Get a list of all files in the <<test>> directory\n",
        "images_names = os.listdir(base_path_test)\n",
        "\n",
        "before_run_time = datetime.now()\n",
        "\n",
        "# Get test_x by vectorization\n",
        "# and test_y by name of each person in the each image name\n",
        "for index, img_name in enumerate(images_names):\n",
        "\n",
        "    img_vector = vertorizing_png_imges(base_path_test + img_name)\n",
        "    test_x.append(img_vector)\n",
        "\n",
        "    img_name = img_name.split(\"-\")\n",
        "    label = img_name[-2]\n",
        "    test_y.append(label)\n",
        "\n",
        "    progress_bar(index, \"test\")\n",
        "\n",
        "after_run_time = datetime.now()\n",
        "diff = after_run_time - before_run_time\n",
        "print(f\"This cell took {int(diff.seconds / 60)} minutes to run.\")"
      ],
      "metadata": {
        "id": "ZzXuPeghXgMg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_x = np.array(train_x)\n",
        "train_y = np.array(train_y)\n",
        "\n",
        "test_x = np.array(test_x)\n",
        "test_y = np.array(test_y)"
      ],
      "metadata": {
        "id": "8PhkN4qUXjFy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "metadata": {
        "id": "oLYsFT-SXlst"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Neural Network"
      ],
      "metadata": {
        "id": "uugnN57bX1rE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating the CNN model\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(21, 33, 3)),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Dropout(0.7),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(18, activation='softmax')\n",
        "])\n",
        "\n",
        "# Setting Adam optimizer\n",
        "optimizer = Adam(learning_rate=0.001)\n",
        "\n",
        "# Compileing the model with the optimizer\n",
        "model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "dRo_SmMDXt6e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "model.fit(train_x, numerical_train_labels, epochs=10, batch_size=32)"
      ],
      "metadata": {
        "id": "Fy0TE6dKXvws"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}